{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8480,"status":"ok","timestamp":1720816642971,"user":{"displayName":"Jay Singhvi","userId":"03351219939534098036"},"user_tz":420},"id":"oXX3FXrk1Hee","outputId":"9b9e6e1d-c192-42cf-bfdf-3bf5b7e37b5b"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# %cd \"/content/drive/MyDrive/computer-vision-plant-detection\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -r requirements.txt\n","# !pip list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dHiOEMoM1Heg"},"outputs":[],"source":["# version 1\n","# from ultralytics import YOLO\n","# import os\n","\n","# # Load a pretrained YOLOv8m model\n","\n","# model = YOLO(\"yolov10x.pt\")\n","\n","# # Train the model with enhanced augmentation\n","\n","# results = model.train(\n","#     data=\"config.yaml\",\n","#     epochs=100,\n","#     imgsz=640,\n","#     batch=4,\n","# )\n","\n","# # Evaluate the model\n","\n","# val_results = model.val()\n","\n","# # The best model is automatically saved during training\n","\n","# best_model_path = os.path.join(results.save_dir, \"weights\", \"best.pt\")\n","\n","# print(f\"Best model saved as: {best_model_path}\")\n","\n","# # Optionally, save the final model explicitly\n","\n","# final_model_path = os.path.join(results.save_dir, \"weights\", \"last.pt\")\n","\n","# print(f\"Final model saved as: {final_model_path}\")\n","\n","# # Optionally, you can run inference on test images\n","\n","# model.predict(source=\"data/images/val/\", save=True, conf=0.25)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# version 2\n","from ultralytics import YOLO\n","import os\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","import yaml\n","\n","# Check for GPU availability and set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","# Load a pretrained YOLOv8s model (smaller model for memory efficiency)\n","model = YOLO(\"yolov10x.pt\").to(device)\n","# Define data augmentation\n","transform = transforms.Compose(\n","    [\n","        transforms.RandomRotation(20),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n","        transforms.RandomResizedCrop(640, scale=(0.8, 1.0)),\n","    ]\n",")\n","# Custom dataset class for plant images\n","\n","\n","class PlantDataset(torch.utils.data.Dataset):\n","    def __init__(self, img_dir, label_dir, transform=None):\n","        self.img_dir = img_dir\n","        self.label_dir = label_dir\n","        self.transform = transform\n","        self.images = [\n","            img\n","            for img in os.listdir(img_dir)\n","            if img.endswith((\".png\", \".jpg\", \".jpeg\"))\n","        ]\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(\n","            self.label_dir, self.images[idx].rsplit(\".\", 1)[0] + \".txt\"\n","        )\n","        image = Image.open(img_path).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","        # Here we're just returning the image path and label path\n","        # YOLO will handle the actual loading and processing\n","        return img_path, label_path\n","\n","\n","# Create custom datasets\n","train_dataset = PlantDataset(\n","    \"data/images/train/\", \"data/labels/train/\", transform=transform\n",")\n","val_dataset = PlantDataset(\"data/images/val/\", \"data/labels/val/\")\n","# Train the model with custom settings\n","results = model.train(\n","    data=\"config.yaml\",\n","    epochs=200,\n","    imgsz=640,\n","    batch=16,\n","    optimizer=\"AdamW\",\n","    lr0=1e-3,\n","    lrf=1e-4,\n","    momentum=0.937,\n","    weight_decay=0.0005,\n","    warmup_epochs=3,\n","    warmup_momentum=0.8,\n","    warmup_bias_lr=0.1,\n","    box=7.5,\n","    cls=0.5,\n","    dfl=1.5,\n","    mixup=0.2,\n","    copy_paste=0.1,\n","    device=device,\n","    amp=True,  # Enable mixed precision training\n","    workers=4,  # Number of worker threads for data loading\n","    cos_lr=True,  # Use cosine learning rate scheduler\n","    # resume=True,  # Resume training from last checkpoint\n","    patience=20,  # Early stopping\n","    val=True,\n","    save_period=5,  # Save model every 5 epochs (replaces val_period)\n",")\n","# Evaluate the model\n","val_results = model.val()\n","# Save the best model\n","best_model_path = os.path.join(results.save_dir, \"weights\", \"best.pt\")\n","print(f\"Best model saved as: {best_model_path}\")\n","# Optionally, save the final model explicitly\n","final_model_path = os.path.join(results.save_dir, \"weights\", \"last.pt\")\n","print(f\"Final model saved as: {final_model_path}\")\n","# Run inference on validation images with confidence threshold\n","model.predict(source=\"data/images/val/\", save=True, conf=0.25, device=device)\n","# Export the model to ONNX format for faster inference\n","model.export(format=\"onnx\", dynamic=True, simplify=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import torch\n","import numpy as np\n","from PIL import Image\n","from ultralytics import YOLO\n","\n","\n","def load_existing_labels(label_path):\n","    with open(label_path, \"r\") as f:\n","        return [line.strip().split() for line in f.readlines()]\n","\n","\n","def convert_yolo_to_bbox(yolo_bbox, img_width, img_height):\n","    x_center, y_center, width, height = map(float, yolo_bbox)\n","    x1 = int((x_center - width / 2) * img_width)\n","    y1 = int((y_center - height / 2) * img_height)\n","    x2 = int((x_center + width / 2) * img_width)\n","    y2 = int((y_center + height / 2) * img_height)\n","    return [x1, y1, x2, y2]\n","\n","\n","def convert_bbox_to_yolo(bbox, img_width, img_height):\n","    x1, y1, x2, y2 = bbox\n","    width = (x2 - x1) / img_width\n","    height = (y2 - y1) / img_height\n","    x_center = (x1 + x2) / (2 * img_width)\n","    y_center = (y1 + y2) / (2 * img_height)\n","    return [x_center, y_center, width, height]\n","\n","\n","def iou(box1, box2):\n","    x1 = max(box1[0], box2[0])\n","    y1 = max(box1[1], box2[1])\n","    x2 = min(box1[2], box2[2])\n","    y2 = min(box1[3], box2[3])\n","    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n","    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n","    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n","    return intersection / (area1 + area2 - intersection)\n","\n","\n","def process_image(image_path, label_path, model, iou_threshold=0.5):\n","    print(f\"Processing image: {image_path}\")\n","    # Load image\n","    img = cv2.imread(image_path)\n","    img_height, img_width = img.shape[:2]\n","    # Load existing labels\n","    existing_labels = load_existing_labels(label_path)\n","    existing_bboxes = [\n","        convert_yolo_to_bbox(label[1:], img_width, img_height)\n","        for label in existing_labels\n","    ]\n","    # Detect plants using YOLO\n","    results = model(img)\n","    new_labels = []\n","    # Check if there are any detections\n","    if len(results) > 0 and len(results[0].boxes) > 0:\n","        for det in results[0].boxes.data:\n","            x1, y1, x2, y2, conf, cls = det.tolist()\n","            if cls == 0:  # Assuming 0 is the class for plants\n","                new_bbox = [int(x1), int(y1), int(x2), int(y2)]\n","                # Check if the new detection overlaps with existing labels\n","                is_new = all(\n","                    iou(new_bbox, existing_bbox) < iou_threshold\n","                    for existing_bbox in existing_bboxes\n","                )\n","                if is_new:\n","                    yolo_bbox = convert_bbox_to_yolo(new_bbox, img_width, img_height)\n","                    new_labels.append([0] + yolo_bbox)\n","                    existing_bboxes.append(\n","                        new_bbox\n","                    )  # Add the new bbox to existing_bboxes\n","    return new_labels\n","\n","\n","def main():\n","    # Load pre-trained YOLO model\n","    model = YOLO(\"runs/detect/train/weights/best.pt\")\n","    val_images_path = \"data/images/val\"\n","    val_labels_path = \"data/labels/val\"\n","    for image_file in os.listdir(val_images_path):\n","        if image_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n","            image_path = os.path.join(val_images_path, image_file)\n","            label_file = os.path.splitext(image_file)[0] + \".txt\"\n","            label_path = os.path.join(val_labels_path, label_file)\n","            new_labels = process_image(image_path, label_path, model)\n","            if new_labels:\n","                # Append new labels to the existing file\n","                with open(label_path, \"a\") as f:\n","                    for label in new_labels:\n","                        f.write(\" \".join(map(str, label)) + \"\\n\")\n","                print(\n","                    f\"Processed {image_file}: {len(new_labels)} new plants detected and labeled\"\n","                )\n","            else:\n","                print(f\"Processed {image_file}: No new plants detected\")\n","\n","\n","main()"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
